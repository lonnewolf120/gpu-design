<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Chapter 1: The Big Picture ‚Äì What is a GPU? | Create Your Own GPU</title>
    <link rel="stylesheet" href="../styles.css" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <style>
        .chapter-content { max-width: 800px; margin: 0 auto; padding: 40px 20px; }
        .chapter-nav { display: flex; justify-content: space-between; margin: 40px 0; padding: 20px; background: var(--panel); border-radius: var(--radius); }
        .figure { margin: 30px 0; padding: 20px; background: #f9f9ff; border-radius: 12px; }
        .figure-caption { font-style: italic; color: var(--muted); margin-top: 10px; text-align: center; }
        .key-takeaway { background: #e8f4fd; border-left: 4px solid #2196f3; padding: 16px; margin: 24px 0; }
        .exercise { background: #fff3e0; border-left: 4px solid #ff9800; padding: 16px; margin: 24px 0; }
        .engineer-note { background: #f3e5f5; border-left: 4px solid #9c27b0; padding: 16px; margin: 24px 0; }
        .mermaid { background: transparent; text-align: center; }
        .comparison-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0; }
        .comparison-card { background: linear-gradient(145deg, #f8f9fa, #e9ecef); padding: 20px; border-radius: 12px; border: 2px solid #dee2e6; }
        .comparison-card.cpu { border-color: #6366f1; background: linear-gradient(145deg, #eef2ff, #e0e7ff); }
        .comparison-card.gpu { border-color: #10b981; background: linear-gradient(145deg, #ecfdf5, #d1fae5); }
        .comparison-card h4 { margin-top: 0; display: flex; align-items: center; gap: 8px; }
        .timeline { position: relative; padding-left: 30px; }
        .timeline::before { content: ''; position: absolute; left: 8px; top: 0; bottom: 0; width: 3px; background: linear-gradient(to bottom, #6366f1, #10b981); }
        .timeline-item { position: relative; margin: 20px 0; padding: 15px; background: #f8f9fa; border-radius: 8px; }
        .timeline-item::before { content: ''; position: absolute; left: -26px; top: 20px; width: 12px; height: 12px; background: #6366f1; border-radius: 50%; border: 3px solid white; box-shadow: 0 0 0 3px #6366f1; }
        .timeline-year { font-weight: bold; color: #6366f1; }
    </style>
</head>
<body>
    <div class="chapter-content">
        <div class="chapter-nav">
            <a href="../index.html">‚Üê Home</a>
            <a href="../table-of-contents.html">Table of Contents</a>
            <a href="chapter-02.html">Next: GPU vs CPU Architecture ‚Üí</a>
        </div>

        <h1>Chapter 1: The Big Picture ‚Äì What is a GPU?</h1>
        
        <div class="meta" style="color: var(--muted); margin: 20px 0;">
            <span>Part I: GPU Fundamentals</span> ‚Ä¢ 
            <span>Reading time: ~30 min</span>
        </div>

        <h2>Introduction</h2>
        <p>
            Graphics Processing Units, or GPUs, have become one of the most important components in modern computing.
            What started as specialized hardware for rendering video games has evolved into a general-purpose parallel 
            computing powerhouse that powers AI training, scientific simulation, cryptocurrency mining, and much more.
        </p>
        
        <p>
            In this chapter, we'll answer the fundamental question: what is a GPU and why does it matter?
        </p>

        <h2>1.1 The Classroom Analogy</h2>

        <p>
            Imagine a university classroom where a professor needs to grade 100 identical multiple-choice exams.
        </p>

        <div class="comparison-grid">
            <div class="comparison-card cpu">
                <h4>üß† CPU Approach</h4>
                <p><strong>The Genius Professor</strong></p>
                <p>One brilliant professor with a photographic memory grades exams sequentially. They:</p>
                <ul>
                    <li>Read and analyze each answer deeply</li>
                    <li>Remember patterns from previous exams</li>
                    <li>Handle any unusual edge case</li>
                    <li>Grade ~3 exams per minute</li>
                </ul>
                <p><strong>Time: ~33 minutes for 100 exams</strong></p>
            </div>
            <div class="comparison-card gpu">
                <h4>‚ö° GPU Approach</h4>
                <p><strong>The Army of TAs</strong></p>
                <p>100 teaching assistants with answer keys work in parallel. They:</p>
                <ul>
                    <li>Each take one exam</li>
                    <li>Follow a simple rubric</li>
                    <li>Can't handle weird edge cases</li>
                    <li>All grade simultaneously</li>
                </ul>
                <p><strong>Time: ~1 minute for 100 exams</strong></p>
            </div>
        </div>

        <p>
            This simple analogy captures the fundamental difference: <strong>CPUs are optimized for sequential 
            complexity, while GPUs are optimized for parallel throughput.</strong>
        </p>

        <div class="figure">
            <div class="mermaid">
flowchart LR
    subgraph CPU["üß† CPU Execution"]
        direction TB
        T1["Task 1"] --> T2["Task 2"] --> T3["Task 3"] --> T4["Task 4"]
    end
    
    subgraph GPU["‚ö° GPU Execution"]
        direction TB
        G1["Task 1"]
        G2["Task 2"]
        G3["Task 3"]
        G4["Task 4"]
    end
    
    style CPU fill:#eef2ff,stroke:#6366f1,stroke-width:2px
    style GPU fill:#ecfdf5,stroke:#10b981,stroke-width:2px
            </div>
            <div class="figure-caption">Figure 1.1: CPU executes tasks sequentially; GPU executes tasks in parallel</div>
        </div>

        <div class="key-takeaway">
            <strong>Key Insight:</strong> GPUs trade single-task performance for massive parallelism. They're not 
            "faster" CPUs ‚Äî they're fundamentally different machines designed for fundamentally different workloads.
        </div>

        <h2>1.2 CPU vs GPU Architecture: The Core Difference</h2>

        <p>
            At the silicon level, CPUs and GPUs look radically different. A CPU dedicates most of its transistors 
            to caches, branch prediction, and out-of-order execution. A GPU spends those transistors on more cores.
        </p>

        <div class="figure">
            <div class="mermaid">
block-beta
    columns 2
    
    block:CPU["CPU Architecture"]:1
        columns 1
        CACHE["üóÑÔ∏è Large Cache (L1/L2/L3)"]
        CTRL["üéõÔ∏è Complex Control Unit"]
        PRED["üîÆ Branch Prediction"]
        OOO["‚ö° Out-of-Order Execution"]
        space
        ALU1["üî¢ Core 1"]
        ALU2["üî¢ Core 2"]
        ALU3["üî¢ Core 3"]
        ALU4["üî¢ Core 4"]
    end
    
    block:GPU["GPU Architecture"]:1
        columns 4
        SM1["SM"] SM2["SM"] SM3["SM"] SM4["SM"]
        SM5["SM"] SM6["SM"] SM7["SM"] SM8["SM"]
        SM9["SM"] SM10["SM"] SM11["SM"] SM12["SM"]
        SM13["SM"] SM14["SM"] SM15["SM"] SM16["SM"]
        SM17["SM"] SM18["SM"] SM19["SM"] SM20["SM"]
        SM21["SM"] SM22["SM"] SM23["SM"] SM24["SM"]
        CTRL2["Simple Scheduler"]:4
        CACHE2["Small Shared Cache"]:4
    end
    
    style CPU fill:#eef2ff,stroke:#6366f1,stroke-width:2px
    style GPU fill:#ecfdf5,stroke:#10b981,stroke-width:2px
            </div>
            <div class="figure-caption">Figure 1.2: CPU vs GPU silicon budget ‚Äî CPUs have few powerful cores; GPUs have many simple cores</div>
        </div>

        <table>
            <thead>
                <tr>
                    <th>Aspect</th>
                    <th>CPU</th>
                    <th>GPU</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Core Count</td>
                    <td>4-64 cores</td>
                    <td>1,000-10,000+ cores</td>
                </tr>
                <tr>
                    <td>Core Complexity</td>
                    <td>Highly complex, out-of-order</td>
                    <td>Simple, in-order</td>
                </tr>
                <tr>
                    <td>Cache Size</td>
                    <td>Large (MB per core)</td>
                    <td>Small (KB per core)</td>
                </tr>
                <tr>
                    <td>Clock Speed</td>
                    <td>3-5 GHz</td>
                    <td>1-2 GHz</td>
                </tr>
                <tr>
                    <td>Latency</td>
                    <td>Low (nanoseconds)</td>
                    <td>High (hidden by parallelism)</td>
                </tr>
                <tr>
                    <td>Throughput</td>
                    <td>Good for sequential</td>
                    <td>Excellent for parallel</td>
                </tr>
            </tbody>
        </table>

        <h2>1.3 A Brief History of GPUs</h2>

        <p>
            The evolution of GPUs from fixed-function graphics chips to general-purpose computing engines is 
            one of the most fascinating stories in computing history.
        </p>

        <div class="timeline">
            <div class="timeline-item">
                <div class="timeline-year">1999 ‚Äî The Birth</div>
                <p>NVIDIA releases the GeForce 256, the first chip marketed as a "GPU." It handled 
                transform and lighting in hardware, offloading work from the CPU.</p>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2001 ‚Äî Programmability</div>
                <p>GeForce 3 introduces programmable shaders. Graphics developers can now write 
                custom programs that run on the GPU ‚Äî a revolutionary concept.</p>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2006 ‚Äî CUDA Revolution</div>
                <p>NVIDIA launches CUDA with the GeForce 8800. Scientists realize they can use 
                GPUs for general-purpose computing (GPGPU). A new era begins.</p>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2012 ‚Äî Deep Learning Explosion</div>
                <p>AlexNet wins ImageNet using CUDA GPUs. The deep learning revolution begins, 
                powered almost entirely by GPU computing.</p>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2020+ ‚Äî AI Dominance</div>
                <p>GPUs become essential for training large language models (GPT, BERT, etc.). 
                NVIDIA's datacenter business exceeds gaming revenue for the first time.</p>
            </div>
        </div>

        <div class="figure">
            <div class="mermaid">
timeline
    title GPU Evolution: From Graphics to General Purpose
    1999 : GeForce 256
         : Fixed-function graphics
    2001 : GeForce 3
         : Programmable shaders
    2006 : GeForce 8800 + CUDA
         : GPGPU computing era begins
    2012 : AlexNet wins ImageNet
         : Deep learning revolution
    2017 : Volta + Tensor Cores
         : AI-specialized hardware
    2022 : H100 + Transformers
         : Large language models
            </div>
            <div class="figure-caption">Figure 1.3: GPU evolution timeline</div>
        </div>

        <h2>1.4 Why Build Your Own GPU?</h2>

        <p>
            You might be thinking: "NVIDIA, AMD, and Intel already make amazing GPUs. Why build my own?"
        </p>

        <p>Here are some great reasons:</p>

        <h3>1. Learning</h3>
        <p>
            Building a GPU teaches you about computer architecture, parallel programming, hardware design, and 
            the entire chip development flow. These skills are valuable across the tech industry.
        </p>

        <h3>2. Custom Accelerators</h3>
        <p>
            Sometimes you need a specialized chip for a specific task. Companies build custom GPUs for:
        </p>
        <ul>
            <li>Edge AI inference (Google's Edge TPU, Tesla's FSD chip)</li>
            <li>Video encoding/decoding</li>
            <li>Networking and packet processing</li>
            <li>Cryptocurrency mining ASICs</li>
        </ul>

        <h3>3. Startup Opportunities</h3>
        <p>
            There's a growing market for domain-specific accelerators. If you can build a chip that's 10√ó better 
            for a specific workload, you might have a business. Examples: Groq (AI inference), Tenstorrent, Cerebras.
        </p>

        <h3>4. Open-Source Hardware</h3>
        <p>
            The open-source hardware movement is growing. Projects like RISC-V show that open ISAs can compete with 
            proprietary ones. We need open GPU designs too!
        </p>

        <div class="figure">
            <div class="mermaid">
mindmap
    root((Why Build<br/>Your Own GPU?))
        Learning
            Computer Architecture
            Parallel Programming
            Hardware Design
            Chip Development Flow
        Custom Accelerators
            Edge AI
            Video Processing
            Networking
            Crypto Mining
        Startup Potential
            Domain-specific chips
            10x performance niches
            Growing VC interest
        Open Hardware
            RISC-V success story
            Community contributions
            Academic research
            </div>
            <div class="figure-caption">Figure 1.4: Reasons to build your own GPU</div>
        </div>

        <div class="key-takeaway">
            <strong>Key Insight:</strong> You don't need to beat NVIDIA at gaming GPUs. Find a niche where 
            specialization matters more than raw performance.
        </div>

        <h2>1.5 GPU Market Landscape</h2>

        <h3>The Big Three</h3>
        
        <h4>NVIDIA</h4>
        <p>
            Market leader in both gaming and AI. Their CUDA ecosystem is the de facto standard for GPU computing. 
            Products range from consumer GeForce cards to datacenter H100 GPUs costing $30,000+ each.
        </p>

        <h4>AMD</h4>
        <p>
            Second-largest player. Radeon for gaming, Instinct for compute. Uses open-source ROCm ecosystem. 
            Strong price/performance in consumer market.
        </p>

        <h4>Intel</h4>
        <p>
            Newcomer with Arc GPUs for gaming and Ponte Vecchio for HPC. Leveraging their fab capabilities 
            and oneAPI software stack.
        </p>

        <h3>Emerging Players</h3>
        <ul>
            <li><strong>Google:</strong> TPUs (Tensor Processing Units) for AI</li>
            <li><strong>Tesla:</strong> FSD (Full Self-Driving) chip</li>
            <li><strong>Apple:</strong> M-series GPU architecture</li>
            <li><strong>Qualcomm:</strong> Adreno for mobile</li>
            <li><strong>Startups:</strong> Groq, Cerebras, Graphcore, Tenstorrent</li>
        </ul>

        <div class="figure">
            <div class="mermaid">
pie showData
    title GPU Market Segments (2024)
    "Gaming" : 35
    "AI/ML Training" : 30
    "Data Center/Cloud" : 20
    "Professional Visualization" : 10
    "Automotive/Edge" : 5
            </div>
            <div class="figure-caption">Figure 1.5: GPU market segment distribution</div>
        </div>

        <h2>1.6 What You'll Learn in This Book</h2>

        <p>
            This book is structured in five parts that take you from concepts to manufacturing:
        </p>

        <div class="figure">
            <div class="mermaid">
flowchart TB
    subgraph Part1["Part I: GPU Fundamentals"]
        C1["Ch 1-5: Architecture & ISA"]
    end
    
    subgraph Part2["Part II: Execution & Scheduling"]
        C2["Ch 6-11: Pipeline & Memory"]
    end
    
    subgraph Part3["Part III: Software & Tooling"]
        C3["Ch 12-14: Compilers & Testing"]
    end
    
    subgraph Part4["Part IV: Hardware Implementation"]
        C4["Ch 15-21: RTL & Synthesis"]
    end
    
    subgraph Part5["Part V: Physical Design"]
        C5["Ch 22-25: Tape-out & Manufacturing"]
    end
    
    Part1 --> Part2 --> Part3 --> Part4 --> Part5
    
    style Part1 fill:#dbeafe,stroke:#3b82f6
    style Part2 fill:#dcfce7,stroke:#22c55e
    style Part3 fill:#fef3c7,stroke:#f59e0b
    style Part4 fill:#fce7f3,stroke:#ec4899
    style Part5 fill:#f3e8ff,stroke:#a855f7
            </div>
            <div class="figure-caption">Figure 1.6: Book structure ‚Äî from concepts to silicon</div>
        </div>

        <h3>Part I: GPU Fundamentals (Chapters 1-5)</h3>
        <p>
            Understanding the "why" and "what" of GPU architecture. You'll learn about parallel execution models, 
            core components, and instruction sets.
        </p>

        <h3>Part II: Execution & Scheduling (Chapters 6-11)</h3>
        <p>
            How GPUs actually run code. Pipeline design, memory systems, scheduling, and specialized units.
        </p>

        <h3>Part III: Software & Tooling (Chapters 12-14)</h3>
        <p>
            The software stack that makes hardware useful. Compilers, drivers, programming models, and testing.
        </p>

        <h3>Part IV: Hardware Implementation (Chapters 15-21)</h3>
        <p>
            Writing actual RTL (Verilog/SystemVerilog), building cores, synthesis, and timing closure. 
            This is where you create the real design.
        </p>

        <h3>Part V: Physical Design & Manufacturing (Chapters 22-25)</h3>
        <p>
            Taking your design from RTL to silicon. Physical design, signoff checks, tape-out, and manufacturing.
        </p>

        <div class="key-takeaway">
            <strong>Learning Path:</strong> Read chapters in order for the first time. On second reading, focus on 
            the parts most relevant to your goals (e.g., skip Part V if you're only simulating).
        </div>

        <h2>1.7 Prerequisites</h2>

        <p>
            This book assumes you have:
        </p>
        <ul>
            <li>Basic programming knowledge (C, C++, or Python)</li>
            <li>Understanding of binary, hex, and basic computer organization</li>
            <li>Familiarity with logic gates (AND, OR, NOT, etc.)</li>
            <li>Willingness to learn Verilog/SystemVerilog (we'll teach you)</li>
        </ul>

        <p>
            If you're a final-year CS student, you're probably ready. If you've taken a computer architecture 
            or digital logic course, you're definitely ready.
        </p>

        <h2>1.8 How to Use This Book</h2>

        <h3>For Students</h3>
        <p>
            Read each chapter thoroughly. Do the exercises. Build the example GPU as you go. Use it as a 
            capstone project or thesis work.
        </p>

        <h3>For Startup Founders</h3>
        <p>
            Focus on Parts I-II for architecture decisions. Skim Part III unless you're building a compiler. 
            Deep-dive Part IV-V when you're ready to build silicon. Use appendices as reference.
        </p>

        <h3>For Hobbyists</h3>
        <p>
            Follow along at your own pace. Skip the heavy math if it's not your thing. Focus on simulation and 
            RTL design. The satisfaction of seeing your GPU run a matrix multiply kernel is incredible!
        </p>

        <div class="exercise">
            <strong>Exercise 1.1:</strong> List three applications where GPUs outperform CPUs and explain why 
            parallel execution helps in each case.
        </div>

        <div class="exercise">
            <strong>Exercise 1.2:</strong> Research one GPU startup (Groq, Cerebras, Graphcore, or Tenstorrent). 
            What niche are they targeting? What's their key innovation?
        </div>

        <div class="exercise">
            <strong>Exercise 1.3:</strong> Install a GPU programming framework (CUDA Toolkit, ROCm, or oneAPI) 
            on your machine. Write a "Hello World" kernel that runs on the GPU.
        </div>

        <h2>1.9 Chapter Summary</h2>

        <p>
            In this chapter, we covered:
        </p>
        <ul>
            <li>What GPUs are and how they differ from CPUs</li>
            <li>The history of GPUs from graphics to general-purpose computing</li>
            <li>Modern applications: AI, gaming, scientific computing, cryptocurrency</li>
            <li>Why building your own GPU is valuable</li>
            <li>The market landscape and key players</li>
            <li>What you'll learn in this book</li>
        </ul>

        <div class="key-takeaway">
            <strong>Next Steps:</strong> In Chapter 2, we'll dive deep into the architectural differences between 
            CPUs and GPUs, exploring how transistor budgets, memory hierarchies, and design philosophies diverge.
        </div>

        <h2>Further Reading</h2>
        <ul>
            <li><a href="#cuda-by-example">"CUDA by Example" by Sanders &amp; Kandrot</a> ‚Äî hands-on GPU programming</li>
            <li><a href="#pmpp">"Programming Massively Parallel Processors" by Hwu et al.</a> ‚Äî comprehensive GPU computing text</li>
            <li><a href="#cuda-guide">NVIDIA's CUDA Programming Guide</a> ‚Äî official documentation</li>
            <li><a href="#hennessy">"Computer Architecture: A Quantitative Approach" by Hennessy &amp; Patterson</a> ‚Äî chapter(s) on GPUs</li>
            <li><a href="#ieee-survey">Papers: "GPUs and the Future of Parallel Computing" (IEEE Micro, 2011)</a> ‚Äî survey and research directions</li>
        </ul>

        <div id="further-reading-notes">
            <h3 id="cuda-by-example">"CUDA by Example" ‚Äî Sanders &amp; Kandrot</h3>
            <p>
                A practical, example-driven introduction to CUDA. Best for beginners who want to learn how to
                write simple kernels, launch them from host code, and understand basic CUDA memory spaces.
                Recommended reading: the first 4 chapters (kernels, threads, memory). Pair with Exercise 1.3.
            </p>
            <p>
                <strong>üì¶ Open-Source Code Resources:</strong>
            </p>
            <ul>
                <li><a href="https://github.com/CodedK/CUDA-by-Example-source-code-for-the-book-s-examples-" target="_blank">Official example code from the book</a> ‚Äî All source code examples, ready to compile and run</li>
                <li><a href="https://github.com/yottaawesome/cuda-by-example" target="_blank">Clean copy with license</a> ‚Äî Well-organized repo with proper licensing</li>
                <li><a href="https://github.com/eegkno/CUDA_by_practice" target="_blank">Practice codes + theory PDF</a> ‚Äî Extended practice exercises with solutions and theory notes</li>
            </ul>

            <h3 id="pmpp">"Programming Massively Parallel Processors" ‚Äî Hwu et al.</h3>
            <p>
                A deeper treatment of GPU architecture and parallel algorithms. Covers SIMD execution,
                memory hierarchies, performance modeling, and optimization techniques.
                Good for readers who want both theory and practical tuning advice.
            </p>
            <p>
                <strong>üì¶ Open-Source Code Resources:</strong>
            </p>
            <ul>
                <li><a href="https://github.com/nvixnu/pmpp__programming_massively_parallel_processors" target="_blank">3rd Edition examples</a> ‚Äî Complete examples and exercises from the 3rd edition</li>
                <li><a href="https://github.com/tugot17/pmpp" target="_blank">4th Edition solutions</a> ‚Äî Full solutions to exercises from the latest (4th) edition</li>
                <li><a href="https://github.com/R100001/Programming-Massively-Parallel-Processors" target="_blank">Multi-edition source code</a> ‚Äî Working CUDA code and benchmarks across multiple editions</li>
            </ul>

            <h3 id="cuda-guide">NVIDIA CUDA Programming Guide</h3>
            <p>
                The authoritative reference for the CUDA programming model, runtime API, and memory model.
                Use this for exact API behavior, compiler flags, and performance recommendations when
                moving from examples to real applications.
            </p>
            <p>
                <strong>üÜì Official Free Documentation:</strong>
            </p>
            <ul>
                <li><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" target="_blank">Online HTML version</a> ‚Äî Always up-to-date, searchable, comprehensive</li>
                <li><a href="https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf" target="_blank">PDF download</a> ‚Äî Latest release (13.1+), perfect for offline reading</li>
            </ul>

            <h3 id="hennessy">"Computer Architecture: A Quantitative Approach" ‚Äî Hennessy &amp; Patterson</h3>
            <p>
                This classic text gives rigorous performance analysis and trade-off discussion. Read the
                sections on vector/SIMD processors and accelerators to gain a quantitative view of
                why GPUs are designed the way they are.
            </p>
            <p>
                <strong>üÜì Freely Accessible Versions:</strong>
            </p>
            <ul>
                <li><a href="https://archive.org/details/computerarchitectureaquantitativeapproach6thedition" target="_blank">6th Edition on Internet Archive</a> ‚Äî Borrow/stream the full text (includes GPU chapters)</li>
                <li>Earlier editions (5th) available through academic repositories and public PDFs</li>
            </ul>

            <h3 id="ieee-survey">"GPUs and the Future of Parallel Computing" (IEEE Micro, 2011)</h3>
            <p>
                A useful survey paper that summarizes the evolution of GPU hardware and research directions
                as of 2011. Good for historical context and for spotting recurring research themes.
            </p>
            <p>
                <strong>üÜì Open-Access Versions:</strong>
            </p>
            <ul>
                <li><a href="https://www.researchgate.net/publication/224262634_GPUs_and_the_Future_of_Parallel_Computing" target="_blank">ResearchGate (full PDF)</a> ‚Äî Free full-text access</li>
                <li><a href="https://research.nvidia.com/publication/2011-09_gpus-and-future-parallel-computing" target="_blank">NVIDIA Research page</a> ‚Äî Abstract and possible PDF download</li>
                <li>Also available via Semantic Scholar and IEEE Xplore (institutional access or author copies)</li>
            </ul>
            
            <div class="key-takeaway" style="margin-top: 30px;">
                <strong>üí° Learning Tip:</strong> Start with the GitHub repos for "CUDA by Example" and "PMPP" ‚Äî 
                they contain all the hands-on code examples you can compile and run immediately. The NVIDIA CUDA 
                Programming Guide is your authoritative reference for detailed API behavior. Use the paper for 
                historical context on GPU evolution.
            </div>
        </div>

        <div class="chapter-nav">
            <a href="../index.html">‚Üê Table of Contents</a>
            <a href="chapter-02.html">Next: GPU vs CPU ‚Üí</a>
        </div>
    </div>

    <script>
        mermaid.initialize({ 
            startOnLoad: true, 
            theme: 'base',
            themeVariables: {
                primaryColor: '#6366f1',
                primaryTextColor: '#1e293b',
                primaryBorderColor: '#4f46e5',
                lineColor: '#64748b',
                secondaryColor: '#10b981',
                tertiaryColor: '#f1f5f9'
            }
        });
    </script>
    <script src="../navigation.js"></script>
</body>
</html>
