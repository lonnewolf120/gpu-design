<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Chapter 9: Thread Scheduling | Create Your Own GPU</title>
    <link rel="stylesheet" href="../styles.css" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <style>
        .chapter-content { max-width: 900px; margin: 0 auto; padding: 40px 20px; }
        .code-block { background: #1e1e1e; color: #d4d4d4; padding: 20px; border-radius: 8px; overflow-x: auto; margin: 20px 0; font-family: monospace; font-size: 13px; }
        .key-takeaway { background: #e8f4fd; border-left: 4px solid #2196f3; padding: 16px; margin: 24px 0; }
        .exercise { background: #fff3e0; border-left: 4px solid #ff9800; padding: 16px; margin: 24px 0; }
        .engineer-note { background: #f3e5f5; border-left: 4px solid #9c27b0; padding: 16px; margin: 24px 0; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
        th { background: #f5f5f5; font-weight: bold; }
        .mermaid { background: white; padding: 20px; border-radius: 8px; border: 1px solid #ddd; margin: 20px 0; }
    </style>
</head>
<body>
    <div class="chapter-content">
        <div style="display: flex; justify-content: space-between; margin: 40px 0; padding: 20px; background: #f5f5f5; border-radius: 8px;">
            <a href="chapter-08.html">← Previous: Memory Coalescing</a>
            <a href="../table-of-contents.html">Table of Contents</a>
            <a href="chapter-10.html">Next: Advanced Execution Units →</a>
        </div>

        <h1>Chapter 9: Thread Scheduling and Latency Hiding</h1>
        
        <div style="color: #999; margin: 20px 0;">
            <span>Part II: Execution & Scheduling</span> • 
            <span>Reading time: ~70 min</span>
        </div>

        <h2>Introduction</h2>

        <p>
            The biggest secret of GPU performance: <strong>Thread scheduling hides latency</strong>.
        </p>

        <p>
            When warp 0 issues a memory load that takes 200 cycles to complete, the GPU doesn't wait. 
            Instead, it switches to warp 1, warp 2, ..., warp 15, doing useful work while warp 0 waits. 
            This chapter explores <strong>how GPUs schedule warps</strong>, hide latency through parallelism, 
            and maintain high throughput even when individual operations take hundreds of cycles.
        </p>

        <h2>9.1 Warp Scheduling Fundamentals</h2>

        <h3>The Scheduler's Three Jobs</h3>

        <ol>
            <li><strong>Select which warp executes:</strong> Round-robin, priority, or other algorithms</li>
            <li><strong>Check readiness:</strong> Is the warp waiting for data/synchronization?</li>
            <li><strong>Issue one instruction:</strong> Send instruction to ALU, memory, or special unit</li>
        </ol>

        <h3>Latency Hiding Through Warp Switching</h3>

        <p>
            GPU utilization comes from having enough warps to cover latency. When one warp waits, others compute:
        </p>

        <div class="mermaid">
            <pre>graph TB
    A["Cycle 1: Warp 0 issues LOAD<br/>200-cycle latency"] -->|Switch| B["Cycles 2-17: Warps 1-15<br/>execute in round-robin"]
    B -->|Switch| C["Cycles 18-200: More warps<br/>executing useful work"]
    C -->|Data arrives| D["Cycle 201: Warp 0 uses<br/>loaded data"]
    D -->|No stall| E["✓ Latency completely hidden<br/>by scheduling other warps"]
    
    style A fill:#ffebee
    style E fill:#c8e6c9</pre>
        </div>

        <h3>Round-Robin Scheduling Example</h3>

        <p>
            Most GPUs use simple round-robin scheduling for predictability and ease of implementation:
        </p>

        <div class="code-block">
<pre>Round-Robin Scheduler (16 warps per SM):

Cycle 1: Warp 0 executes instruction
Cycle 2: Warp 1 executes instruction
Cycle 3: Warp 2 executes instruction
...
Cycle 16: Warp 15 executes instruction
Cycle 17: Warp 0 executes next instruction (back to start)

Each warp gets one instruction slot every 16 cycles.
Effective throughput: 1 instruction per warp per 16 cycles.